{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to blast sequence using blast api\n",
    "from Bio.Blast import NCBIWWW\n",
    "\n",
    "sequence_data = open(\"1seq.fasta\").read()\n",
    "sequence_data\n",
    "result_handle = NCBIWWW.qblast(\"blastp\", \"nr\",sequence_data, hitlist_size=1000) \n",
    "\n",
    "with open('results.xml', 'w') as save_file: \n",
    "    blast_results = result_handle.read() \n",
    "    save_file.write(blast_results)\n",
    "#doing this code from terminal using standalone blast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fbdf1d30a42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#list1.pop(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtrialdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mtrial_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrecord\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mPanel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"module 'pandas' has no attribute '{}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "from Bio.Blast import NCBIXML\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "workbook = xlsxwriter.Workbook('parseddata_900.xlsx') \n",
    "worksheet = workbook.add_worksheet()\n",
    "#open the results file\n",
    "result=open(\"res_900.xml\",\"r\")\n",
    "records= NCBIXML.parse(result)\n",
    "item=records\n",
    "\n",
    "\n",
    "\n",
    "alignments=[]\n",
    "start=[]\n",
    "end=[]\n",
    "linker=[]\n",
    "matched_indexes=[]\n",
    "qid=[]           \n",
    "allq=[]\n",
    "defn=[]\n",
    "\n",
    "seqlist=[]\n",
    "s=[]\n",
    "f=open(\"seqs_900.txt\", \"r\")\n",
    "ksj= 1\n",
    "for line in f.readlines():\n",
    "    if ksj % 2 == 0 :\n",
    "        seqlist.append(line.rstrip())\n",
    "    ksj += 1\n",
    "\n",
    "#list1.pop(0)\n",
    "ks=0\n",
    "trialdf=pd.Dataframe()\n",
    "trial_2=pd.Dataframe()\n",
    "for record in records:\n",
    "    allq.append(record.query)\n",
    "    for alignment in record.alignments:\n",
    "        for hsp in alignment.hsps:\n",
    "            start=[]\n",
    "            #only first hsp is taken for each hit, this is the hsp with the best score\n",
    "            if alignment.hit_def:\n",
    "                start.append(seqlist[ks])\n",
    "            \n",
    "            start.append(hsp.query_start)\n",
    "            start.append(hsp.query_end)\n",
    "            start.append(alignment.hit_def)\n",
    "            trialdf=pd.DataFrame({\"seq\":pd.Series(start[0]), \"start\":pd.Series(start[1]),\"end\":pd.Series(start[2]),\"alignment\":pd.Series(start[3])})\n",
    "            trial_2.append(trialdf) \n",
    "            allq.append(\"\\n\")\n",
    "            break\n",
    "    ks=ks+1\n",
    "    allq.pop()\n",
    "    #worksheet.write_column('A1', allq)\n",
    "    #worksheet.write_column('C1', s)\n",
    "    #worksheet.write_column('D1', start)\n",
    "    #worksheet.write_column('E1', end)\n",
    "    #worksheet.write_column('F1', defn)\n",
    "    \n",
    "trial_2.to_excel('trial_1p.xlsx', index=False)    \n",
    "#check for any anomaly\n",
    "#print(len(start))\n",
    "#print(len(end))\n",
    "#print(len(alignments))\n",
    "\n",
    "        \n",
    "workbook.close()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gene'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gene'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-16c4521e9db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gene_dictionary.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gene'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmain_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gene'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'parseddata.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2962be693ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mgcf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m4500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncterminal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindcnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrRow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0mstrRow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mgcf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2962be693ba6>\u001b[0m in \u001b[0;36mncterminal\u001b[0;34m(gcf, indcnt, strRow)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m#get the parsed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mwb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parseddata.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'parseddata.xlsx'"
     ]
    }
   ],
   "source": [
    "gcf=500\n",
    "indcnt=0\n",
    "strRow=0\n",
    "x=0\n",
    "def ncterminal(gcf,indcnt, strRow):\n",
    "\n",
    "    \n",
    "    import xlrd\n",
    "    import xlsxwriter\n",
    "    import re\n",
    "    from Bio.Blast import NCBIXML\n",
    "    #To store the c and n terminal of all the fusion proteins in 2 lists\n",
    "    ntermprtn=[]  \n",
    "    ctermprtn=[]\n",
    "    start=[]\n",
    "    end=[]\n",
    "    defn=[]\n",
    "    alignments=[]\n",
    "    \n",
    "\n",
    "\n",
    "    #get the parsed data                                         \n",
    "    wb2 = xlrd.open_workbook(\"parseddata.xlsx\") \n",
    "    sheet = wb2.sheet_by_index(0) \n",
    "    for i in range(gcf): \n",
    "        start.append(sheet.cell_value(i,3))\n",
    "    for i in range(gcf): \n",
    "        end.append(sheet.cell_value(i,4))\n",
    "    for i in range(gcf): \n",
    "        defn.append(sheet.cell_value(i,5))\n",
    "    for i in range(gcf): \n",
    "        alignments.append(sheet.cell_value(i,2))\n",
    "    for i in range(gcf): \n",
    "        ntermprtn.append(sheet.cell_value(i,0))\n",
    "    for i in range(gcf): \n",
    "        ctermprtn.append(sheet.cell_value(i,1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    patc=ctermprtn[indcnt]#will have to loop for multiple proteins\n",
    "    \n",
    "\n",
    "    #creating dictionary to understand the alignment definition line\n",
    "    excel_file = 'genedict_jan14.xlsx'\n",
    "    book = xlrd.open_workbook(excel_file)\n",
    "    sheet = book.sheet_by_index(0)\n",
    "    ensembl1=0\n",
    "    gene1=1\n",
    "    gene_syn1 = 2 \n",
    "    gene_desc1 = 3\n",
    "    uniprot1 = 4\n",
    "\n",
    "    gene_syn=[]\n",
    "    gene_desc=[]\n",
    "    uniprot=[]\n",
    "    ensembl=[]\n",
    "    gene=[]\n",
    "\n",
    "    for row in range(sheet.nrows):\n",
    "        gene_syn.append(sheet.cell(row,gene_syn1).value) \n",
    "        gene_desc.append(sheet.cell(row,gene_desc1).value)\n",
    "        uniprot.append(sheet.cell(row,uniprot1).value)\n",
    "        ensembl.append(sheet.cell(row,ensembl1).value)\n",
    "        gene.append(sheet.cell(row,gene1).value)\n",
    "\n",
    "    gsc=[] \n",
    "    gdc=[]\n",
    "    upc=[]\n",
    "    enc=[]\n",
    "    gec=[s for s in gene if patc in s]\n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "    if gec != []:\n",
    "        element=gec[0]\n",
    "        indexdict=gene.index(element)\n",
    "    else:\n",
    "        print('Error: Dictionary does not have C terminal protein: '+ patc)\n",
    "\n",
    "    \n",
    "    gdc=gene_desc[indexdict]\n",
    "    gdc=gdc.split(\",\")\n",
    "    gsc=gene_syn[indexdict]\n",
    "    gsc=gsc.split(\",\")\n",
    "    upc.append(uniprot[indexdict])\n",
    "    enc.append(ensembl[indexdict])\n",
    "\n",
    "\n",
    "    i=0\n",
    "\n",
    "\n",
    "    matchc=[]\n",
    "\n",
    "    h=0\n",
    "\n",
    "    for i in defn:\n",
    "        titlestr=defn[h]\n",
    "        if gsc != []:\n",
    "            if titlestr.find(gsc[0]) != -1:\n",
    "                #print('gene syn')\n",
    "                matchc.append(defn.index(titlestr))\n",
    "        if gdc != []:\n",
    "            if titlestr.find(gdc[0]) != -1:\n",
    "                #print('desc')\n",
    "                matchc.append(defn.index(titlestr))\n",
    "        if upc != []:\n",
    "            if titlestr.find(upc[0]) != -1:\n",
    "                #print('uniprot')\n",
    "                matchc.append(defn.index(titlestr))\n",
    "        if enc != []:\n",
    "            if titlestr.find(enc[0]) != -1:\n",
    "                #print('ensembl')\n",
    "                matchc.append(defn.index(titlestr))\n",
    "        if gec != []:\n",
    "            if titlestr.find(gec[0]) != -1:\n",
    "                #print('gene')\n",
    "                matchc.append(defn.index(titlestr))\n",
    "        h=h+1\n",
    "\n",
    "    #print('this is matchc:')\n",
    "    #print(matchc)\n",
    "\n",
    "\n",
    "    #finalc = [s for s in defn if pat in s]\n",
    "    #To get the hit definition and match it for homo sapiens and the n terminal protein\n",
    "\n",
    "\n",
    "    patn=ntermprtn[indcnt] #will have to loop for multiple proteins\n",
    "    #matchhsn = [s for s in defnn if \"Homo sapiens\" in s]\n",
    "    #finaln = [s for s in defn if pat in s]\n",
    "\n",
    " \n",
    "\n",
    "    gsn=[] \n",
    "    gdn=[]\n",
    "    upn=[]\n",
    "    enn=[]\n",
    "    gen=[s for s in gene if patn in s]\n",
    "  \n",
    "    \n",
    "    \n",
    "    if gen != []:\n",
    "        element=gen[0]\n",
    "        \n",
    "        indexdictn=gene.index(element)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        print('Error: The dictionary does not contain N terminal protein: hhhhhh'+ patn)\n",
    "    \n",
    "    \n",
    "\n",
    "    gdn=gene_desc[indexdictn]\n",
    "    gdn=gdn.split(\",\")\n",
    "    gsn=gene_syn[indexdictn]\n",
    "    gsn=gsn.split(\",\")\n",
    "    upn.append(uniprot[indexdictn])\n",
    "    enn.append(ensembl[indexdictn])\n",
    "\n",
    "    print(\"***********\")\n",
    "    print(enn)\n",
    "    matchn=[]\n",
    "\n",
    "    h=0\n",
    "\n",
    "    for i in defn:\n",
    "        titlestr=defn[h]\n",
    "        if gsn != []:\n",
    "            if titlestr.find(gsn[0]) != -1:\n",
    "                #print(titlestr)\n",
    "                matchn.append(defn.index(titlestr))\n",
    "        if gdn != []:\n",
    "            if titlestr.find(gdn[0]) != -1:\n",
    "                #print(titlestr)\n",
    "                matchn.append(defn.index(titlestr))\n",
    "        if upn != []:\n",
    "            if titlestr.find(upn[0]) != -1:\n",
    "                #print(titlestr)\n",
    "                matchn.append(defn.index(titlestr))\n",
    "        if enn != []:\n",
    "            if titlestr.find(enn[0]) != -1:\n",
    "                #print(titlestr)\n",
    "                matchn.append(defn.index(titlestr))\n",
    "        if gen != []:\n",
    "            if titlestr.find(gen[0]) != -1:\n",
    "                #print(titlestr)\n",
    "                matchn.append(defn.index(titlestr))\n",
    "        h=h+1\n",
    "\n",
    "    #print('This is matchn:')\n",
    "    #print(matchn)\n",
    "\n",
    "    #store the indices of the matches in a list\n",
    "\n",
    "\n",
    "    end_match_c=[]\n",
    "    end_match_n=[]\n",
    "    start_match_n=[]\n",
    "    start_match_c=[]\n",
    "    im=0\n",
    "    ik=0\n",
    "\n",
    "    while ik < len(matchc):   \n",
    "        end_match_c.append(end[matchc[ik]])\n",
    "        ik=ik+1\n",
    "    \n",
    "    while im < len(matchn):   \n",
    "        end_match_n.append(end[matchn[im]])\n",
    "        im=im+1\n",
    "    #print(end_match_n)\n",
    "    ik=0\n",
    "    im=0\n",
    "    while ik < len(matchc):   \n",
    "        start_match_c.append(start[matchc[ik]])\n",
    "        ik=ik+1\n",
    "    while im < len(matchn):   \n",
    "        start_match_n.append(start[matchn[im]])\n",
    "        im=im+1\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    #matches={}\n",
    "    #matches['Start N']=start_match_n\n",
    "    #matches['Start C']=start_match_c\n",
    "    #matches['End N']=end_match_n\n",
    "    #matches['End C']=end_match_c\n",
    "\n",
    "    #print('this is a dictionary of all matches:')\n",
    "    #print(matches)\n",
    "    fusprtn=[]\n",
    "    fusprtn.append(patn+\"/\"+patc+str(indcnt))\n",
    "    \n",
    "    workbook = xlsxwriter.Workbook('Linkdata.xlsx') \n",
    "    worksheet = workbook.add_worksheet()\n",
    "    m=max(len(fusprtn),len(start_match_n),len(end_match_n),len(start_match_c),len(end_match_c))\n",
    "    m1=m\n",
    "    m=m+strRow\n",
    "    a=0\n",
    "    row=strRow\n",
    "    while row<m and a<m1:\n",
    "        worksheet.write(row,'A1', fusprtn[a])\n",
    "        worksheet.write(row,'B1', start_match_n[a])\n",
    "        worksheet.write(row,'C1', end_match_n[a])\n",
    "        worksheet.write(row,'D1', start_match_c[a])\n",
    "        worksheet.write(row,'E1', end_match_c[a])\n",
    "        row=row+1\n",
    "        a=a+1\n",
    "    \n",
    "    #df = pd.DataFrame({'Protein': pd.Series(fusprtn), 'Start N': pd.Series(start_match_n), 'End N': pd.Series(end_match_n), 'Start C': pd.Series(start_match_c), 'End C': pd.Series(end_match_c)})\n",
    "    #print (df)\n",
    "    #sheet_name='Sheet1'\n",
    "    #df.to_csv('linkerdat.csv', sheet_name, na_rep='None', startrow=strRow, engine='openpyxl' )\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "        #df.to_excel('linkerdata.xlsx', index=False)\n",
    "        # start and end points put into and excel file\n",
    "        \n",
    "    #sheet_name='Sheet1'\n",
    "    #append_df_to_excel('linkerdata.xlsx', df, sheet_name, startrow)\n",
    "    strRow=strRow+len(df)+1\n",
    "    return strRow\n",
    "\n",
    "\n",
    "while gcf <= 4500:  \n",
    "    x=ncterminal(gcf,indcnt,strRow)\n",
    "    strRow=x\n",
    "    gcf=gcf+500\n",
    "    indcnt=indcnt+500\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_excel(filename, df, sheet_name, startrow, truncate_sheet=False, index=False, **to_excel_kwargs):\n",
    "   \n",
    "        from openpyxl import load_workbook\n",
    "\n",
    "        import pandas as pd\n",
    "\n",
    "        # ignore [engine] parameter if it was passed\n",
    "        if 'engine' in to_excel_kwargs:\n",
    "            to_excel_kwargs.pop('engine')\n",
    "            \n",
    "        writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "    # Python 2.x: define [FileNotFoundError] exception if it doesn't exist \n",
    "        try:\n",
    "            FileNotFoundError\n",
    "        except NameError:\n",
    "            FileNotFoundError = IOError\n",
    "\n",
    "\n",
    "        try:\n",
    "            # try to open an existing workbook\n",
    "            writer.book = load_workbook(filename)\n",
    "\n",
    "            # get the last row in the existing Excel sheet\n",
    "            # if it was not specified explicitly\n",
    "            if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "                startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "            # truncate sheet\n",
    "            if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "                # index of [sheet_name] sheet\n",
    "                idx = writer.book.sheetnames.index(sheet_name)\n",
    "                # remove [sheet_name]\n",
    "                writer.book.remove(writer.book.worksheets[idx])\n",
    "                # create an empty sheet [sheet_name] using old index\n",
    "                writer.book.create_sheet(sheet_name, idx)\n",
    "\n",
    "            # copy existing sheets\n",
    "            writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "        except FileNotFoundError:\n",
    "            # file does not exist yet, we will create it\n",
    "            pass\n",
    "\n",
    "        if startrow is None:\n",
    "            startrow = 0\n",
    "\n",
    "        # write out the new sheet\n",
    "        df.to_excel(writer, sheet_name, startrow, **to_excel_kwargs)\n",
    "\n",
    "        # save the workbook\n",
    "        writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_df_to_excel(filename, df, sheet_name='Sheet1', startrow=None,\n",
    "                       truncate_sheet=False, \n",
    "                       **to_excel_kwargs):\n",
    "    \"\"\"\n",
    "    Append a DataFrame [df] to existing Excel file [filename]\n",
    "    into [sheet_name] Sheet.\n",
    "    If [filename] doesn't exist, then this function will create it.\n",
    "\n",
    "    Parameters:\n",
    "      filename : File path or existing ExcelWriter\n",
    "                 (Example: '/path/to/file.xlsx')\n",
    "      df : dataframe to save to workbook\n",
    "      sheet_name : Name of sheet which will contain DataFrame.\n",
    "                   (default: 'Sheet1')\n",
    "      startrow : upper left cell row to dump data frame.\n",
    "                 Per default (startrow=None) calculate the last row\n",
    "                 in the existing DF and write to the next row...\n",
    "      truncate_sheet : truncate (remove and recreate) [sheet_name]\n",
    "                       before writing DataFrame to Excel file\n",
    "      to_excel_kwargs : arguments which will be passed to `DataFrame.to_excel()`\n",
    "                        [can be dictionary]\n",
    "\n",
    "    Returns: None\n",
    "    \"\"\"\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # ignore [engine] parameter if it was passed\n",
    "    if 'engine' in to_excel_kwargs:\n",
    "        to_excel_kwargs.pop('engine')\n",
    "\n",
    "    writer = pd.ExcelWriter(filename, engine='openpyxl')\n",
    "\n",
    "    # Python 2.x: define [FileNotFoundError] exception if it doesn't exist \n",
    "    try:\n",
    "        FileNotFoundError\n",
    "    except NameError:\n",
    "        FileNotFoundError = IOError\n",
    "\n",
    "\n",
    "    try:\n",
    "        # try to open an existing workbook\n",
    "        writer.book = load_workbook(filename)\n",
    "\n",
    "        # get the last row in the existing Excel sheet\n",
    "        # if it was not specified explicitly\n",
    "        if startrow is None and sheet_name in writer.book.sheetnames:\n",
    "            startrow = writer.book[sheet_name].max_row\n",
    "\n",
    "        # truncate sheet\n",
    "        if truncate_sheet and sheet_name in writer.book.sheetnames:\n",
    "            # index of [sheet_name] sheet\n",
    "            idx = writer.book.sheetnames.index(sheet_name)\n",
    "            # remove [sheet_name]\n",
    "            writer.book.remove(writer.book.worksheets[idx])\n",
    "            # create an empty sheet [sheet_name] using old index\n",
    "            writer.book.create_sheet(sheet_name, idx)\n",
    "\n",
    "        # copy existing sheets\n",
    "        writer.sheets = {ws.title:ws for ws in writer.book.worksheets}\n",
    "    except FileNotFoundError:\n",
    "        # file does not exist yet, we will create it\n",
    "        pass\n",
    "\n",
    "    if startrow is None:\n",
    "        startrow = 0\n",
    "\n",
    "    # write out the new sheet\n",
    "    df.to_excel(writer, sheet_name, startrow=startrow, **to_excel_kwargs)\n",
    "\n",
    "    # save the workbook\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to get longest and shortest linker length\n",
    "t=0\n",
    "e=0\n",
    "for t in range(len(matched_indexes_c)):\n",
    "    for e in range(len(matched_indexes_n)):\n",
    "        linker.append(end[matched_indexes_c[t]]-start[matched_indexes_n[e]]) \n",
    "#remove duplicates\n",
    "finlinker = [] \n",
    "for i in linker: \n",
    "    if i not in finlinker: \n",
    "        finlinker.append(i) \n",
    "        \n",
    "largest= max(finlinker)\n",
    "smallest= min(finlinker)\n",
    "print(finlinker)\n",
    "\n",
    "\n",
    "#version2\n",
    "\n",
    "print('++++++++++++++++++++++++++++++++++++++++++++')\n",
    "t=0\n",
    "e=0\n",
    "for t in range(len(start_match_n)):\n",
    "    for e in range(len(end_match_c)):\n",
    "        linker.append(end_match_c[e]-start_match_n[t]) \n",
    "#remove duplicates\n",
    "finlinker = [] \n",
    "for i in linker: \n",
    "    if i not in finlinker: \n",
    "        finlinker.append(i) \n",
    "        \n",
    "largest= max(finlinker)\n",
    "smallest= min(finlinker)\n",
    "print(finlinker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
